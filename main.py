# main.py
import logging
import argparse
import os
import sqlite3
import pandas as pd

from services.recommendation_service import content_based_recommendations
from services.collaborative_service import build_model, get_recommendations
from services.analyze_service import analyze_student_readiness
from markdown_report import save_markdown_report, save_readiness_report
from repository import task_repo
from db import load_data
from validator import run_all

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
os.makedirs("logs", exist_ok=True)
logging.basicConfig(
    filename="logs/system.log",
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    encoding="utf-8"
)

# –ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
parser = argparse.ArgumentParser(description="Recommendation System")
parser.add_argument('--student-id', type=int, help='ID —Å—Ç—É–¥–µ–Ω—Ç–∞')
parser.add_argument('--mode', type=str, choices=['content', 'collab', 'hybrid'], help='–¢–∏–ø —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π')
parser.add_argument('--export-path', type=str, help='–ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –≤ CSV')
args = parser.parse_args()

# –ó–∞–ø—Ä–æ—Å—ã, –µ—Å–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã
student_id = args.student_id if args.student_id else int(input("–í–≤–µ–¥–∏—Ç–µ ID —Å—Ç—É–¥–µ–Ω—Ç–∞: "))
mode = args.mode
if not mode:
    print("–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π:")
    print("1. Content-Based")
    print("2. Collaborative Filtering")
    print("3. –ì–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
    choice = input("–í–∞—à –≤—ã–±–æ—Ä (1/2/3): ")
    mode = {'1': 'content', '2': 'collab', '3': 'hybrid'}.get(choice)

logging.info(f"–ó–∞–ø—É—Å–∫ —Å–∏—Å—Ç–µ–º—ã –¥–ª—è student_id={student_id}, —Ä–µ–∂–∏–º={mode}")

# –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ –ë–î
students, tasks, lessons, lesson_tasks, exam_results, exam_tasks, student_theme_progress = load_data()
with sqlite3.connect("your_database.db") as conn:
    forms = pd.read_sql_query("SELECT * FROM Forms", conn)

# –í–∞–ª–∏–¥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
run_all(tasks, forms, students, student_theme_progress)

recommendations = pd.DataFrame()

if mode == "content":
    recommendations = content_based_recommendations(student_id)
    logging.info(f"Content-Based: –ø–æ–ª—É—á–µ–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(recommendations)}")
    print("\nContent-Based —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print(recommendations if not recommendations.empty else "–ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.")

elif mode == "collab":
    model, matrix = build_model(exam_results)
    if model:
        recommendations = get_recommendations(student_id, model, matrix, exam_tasks, tasks)
        logging.info(f"Collaborative Filtering: –ø–æ–ª—É—á–µ–Ω–æ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: {len(recommendations)}")
        print("\nCollaborative Filtering —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
        print(recommendations if not recommendations.empty else "–ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.")
    else:
        logging.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å —Å–æ–≤–º–µ—Å—Ç–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –º–æ–¥–µ–ª—å.")

elif mode == "hybrid":
    model, matrix = build_model(exam_results)
    cb_recs = content_based_recommendations(student_id)
    cf_recs = get_recommendations(student_id, model, matrix, exam_tasks, tasks) if model else pd.DataFrame()

    hybrid = pd.concat([cb_recs, cf_recs]).drop_duplicates(subset='id', keep='first')
    themes = task_repo.get_themes()
    if 'theme_name' not in hybrid.columns:
        hybrid = hybrid.merge(themes, on='theme_id', how='left')
    else:
        hybrid = hybrid.drop(columns='theme_name').merge(themes, on='theme_id', how='left')

    recommendations = hybrid
    logging.info(f"–ì–∏–±—Ä–∏–¥–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ–ª—É—á–µ–Ω–æ: {len(recommendations)}")
    print("\n–ì–∏–±—Ä–∏–¥–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print(recommendations if not recommendations.empty else "–ù–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π.")

else:
    logging.warning(f"–ù–µ–≤–µ—Ä–Ω—ã–π –≤–≤–æ–¥ —Ä–µ–∂–∏–º–∞: {mode}")
    print("–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≤—ã–±–æ—Ä.")

# –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω –ø—É—Ç—å
if args.export_path and not recommendations.empty:
    try:
        recommendations.to_csv(args.export_path, index=False)
        logging.info(f"–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {args.export_path}")
        print(f"\n–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {args.export_path}")

        # Markdown-–æ—Ç—á–µ—Ç
        md_path = args.export_path.replace('.csv', '.md')
        save_markdown_report(recommendations, md_path, student_id)

        # –ê–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
        readiness_df = analyze_student_readiness(student_id)
        readiness_path = args.export_path.replace('.csv', '_readiness.csv')
        readiness_df.to_csv(readiness_path, index=False)
        print(f"üß† –ê–Ω–∞–ª–∏–∑ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {readiness_path}")

        # Markdown –ø–æ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
        readiness_md = readiness_path.replace('.csv', '.md')
        save_readiness_report(readiness_df, readiness_md, student_id)

    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ CSV: {e}")
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")